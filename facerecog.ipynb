{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Initialize MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def preprocess_face(image):\n",
    "    try:\n",
    "        # Convert the image from float32 back to uint8\n",
    "        image = np.uint8(image * 255.0)\n",
    "        with mp_face_detection.FaceDetection(min_detection_confidence=0.2) as face_detection:\n",
    "            # Convert the image from BGR to RGB as MediaPipe uses RGB images\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # Process the image and detect faces\n",
    "            results = face_detection.process(image_rgb)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    # Extract bounding box information\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = image.shape\n",
    "                    bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                           int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "\n",
    "                    # Extract the face region\n",
    "                    face = image[bbox[1]:bbox[1] + bbox[3], bbox[0]:bbox[0] + bbox[2]]\n",
    "\n",
    "                    # Resize the face region to the desired size (224x224)\n",
    "                    face_resized = cv2.resize(face, (224, 224))\n",
    "\n",
    "                    return face_resized\n",
    "\n",
    "        # If no faces are detected, return the original resized image\n",
    "        return cv2.resize(image, (224, 224))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocess_face: {e}\")\n",
    "        return cv2.resize(image, (224, 224))\n",
    "\n",
    "def preprocess_function(image):\n",
    "    image = preprocess_face(image)\n",
    "    return image / 255.0  # Normalize the image\n",
    "\n",
    "# Create ImageDataGenerators for training and validation datasets with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_function,\n",
    "\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_function\n",
    ")\n",
    "\n",
    "# Load training dataset from person1 and person2 directories\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    'dataset/train/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load validation dataset from person1 and person2 directories\n",
    "validation_dataset = validation_datagen.flow_from_directory(\n",
    "    'dataset/validation/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load the VGG16 model with pre-trained weights from the local file and exclude the top layers\n",
    "base_model = VGG16(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# Add new top layers for fine-tuning\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Fine-tune the model\n",
    "model_fit = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=train_dataset.samples // 8,\n",
    "    epochs=20,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=validation_dataset.samples // 8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict and display image with predicted class\n",
    "def predict_and_display_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    X = tf.keras.applications.vgg16.preprocess_input(X)\n",
    "    \n",
    "    # Predict the class\n",
    "    prediction = model.predict(X)\n",
    "    print(f\"Raw model output: {prediction[0][0]}\")\n",
    "    \n",
    "    # Determine the class based on prediction confidence\n",
    "    if prediction[0][0] < 0.1:\n",
    "        print(\"Predicted class: Marcus\")\n",
    "    elif prediction[0][0] > 0.9:\n",
    "        print(\"Predicted class: Ronaldo\")\n",
    "    else:\n",
    "        print(\"Predicted class: Unknown\")\n",
    "\n",
    "# Predicting on new images in the test folder\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "for i in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, i)\n",
    "    if img_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        predict_and_display_image(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
